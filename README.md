# fromPodtoCast

SoluciÃ³n completa para crear datasets de entrenamiento para modelos TTS (Text-to-Speech) a partir de podcasts. Incluye bÃºsqueda automÃ¡tica en YouTube, descarga, procesamiento y generaciÃ³n de datos de entrenamiento.

## ğŸš€ CaracterÃ­sticas Principales

### Pipeline AutomÃ¡tico (`auto_pipeline.py`)
- **BÃºsqueda en YouTube**: Busca podcasts por categorÃ­as configurables
- **Descarga automÃ¡tica**: Descarga y convierte a WAV automÃ¡ticamente
- **Procesamiento completo**: DiarizaciÃ³n, segmentaciÃ³n, transcripciÃ³n y verificaciÃ³n
- **Registro de progreso**: Evita duplicados y permite retomar procesos fallidos
- **GeneraciÃ³n de reportes**: GrÃ¡ficas visuales del procesamiento

### Procesamiento de Audio (`main.py`)
- **SegmentaciÃ³n inteligente**: Divide podcasts en segmentos de 5-15 segundos
- **NormalizaciÃ³n de audio**: Ajusta sample rate (22050 Hz), niveles LUFS (-23.0)
- **DiarizaciÃ³n de hablantes**: Identifica y etiqueta diferentes narradores
- **Voice Bank global**: Reutiliza IDs de hablantes entre podcasts

### TranscripciÃ³n y Texto
- **Whisper**: TranscripciÃ³n automÃ¡tica con detecciÃ³n de idioma
- **Preprocesamiento**: CorrecciÃ³n de puntuaciÃ³n, nÃºmeros, espaciado
- **CorrecciÃ³n LLM**: VerificaciÃ³n y correcciÃ³n con modelos de lenguaje (Ollama)

### Optimizaciones LLM (Nuevo)
- **Batch Processing**: Procesa mÃºltiples textos en una sola llamada (80% menos HTTP calls)
- **CachÃ© Persistente**: Evita reprocesar textos idÃ©nticos entre sesiones
- **Procesamiento Paralelo**: ThreadPoolExecutor para correcciones simultÃ¡neas
- **ValidaciÃ³n Pydantic**: Schemas tipados para respuestas del LLM y metadata

## ğŸ“ Estructura del Proyecto

```
fromPodtoCast/
â”œâ”€â”€ main.py                    # Procesador principal de audio
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.json            # ConfiguraciÃ³n del procesador
â”‚   â”œâ”€â”€ search_queries.json    # CategorÃ­as de bÃºsqueda para auto_pipeline
â”‚   â””â”€â”€ glosario_terminos.json # TÃ©rminos tÃ©cnicos para correcciÃ³n
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ auto_pipeline.py       # Pipeline automÃ¡tico completo
â”‚   â”œâ”€â”€ download_video.py      # Descarga de videos/audio
â”‚   â””â”€â”€ check_dependencies.py  # Verificador de dependencias
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ processor.py           # Orquestador del pipeline
â”‚   â”œâ”€â”€ audio_segmenter.py     # SegmentaciÃ³n de audio
â”‚   â”œâ”€â”€ audio_normalizer.py    # NormalizaciÃ³n de audio
â”‚   â”œâ”€â”€ transcriber.py         # TranscripciÃ³n con Whisper
â”‚   â”œâ”€â”€ speaker_diarizer.py    # DiarizaciÃ³n de hablantes
â”‚   â”œâ”€â”€ segment_reviewer.py    # RevisiÃ³n de segmentos
â”‚   â”œâ”€â”€ voice_bank.py          # GestiÃ³n de voces conocidas
â”‚   â”œâ”€â”€ text_preprocessor.py   # Preprocesamiento de texto
â”‚   â”œâ”€â”€ text_corrector_llm.py  # CorrecciÃ³n con LLM (optimizado)
â”‚   â”œâ”€â”€ correction_cache.py    # CachÃ© de correcciones LLM
â”‚   â””â”€â”€ models/                # Schemas Pydantic
â”‚       â”œâ”€â”€ llm_schemas.py     # ValidaciÃ³n de respuestas LLM
â”‚       â””â”€â”€ metadata_schemas.py # ValidaciÃ³n de metadata
â””â”€â”€ docs/                      # DocumentaciÃ³n adicional
```

## ğŸ› ï¸ InstalaciÃ³n

### Requisitos
- Python 3.8+
- FFmpeg (para procesamiento de audio)
- CUDA (opcional, para aceleraciÃ³n GPU)

### Pasos

```bash
# 1. Clonar el proyecto
cd /home/ttech-main/fromPodtoCast

# 2. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Verificar dependencias
python scripts/check_dependencies.py
```

## ğŸ“– Uso

### 1. Pipeline AutomÃ¡tico (Recomendado)

El script `auto_pipeline.py` automatiza todo el proceso: bÃºsqueda, descarga y procesamiento.

```bash
# Buscar, descargar y procesar 20 videos
python scripts/auto_pipeline.py --videos 20

# Ver quÃ© videos se encontrarÃ­an (sin descargar)
python scripts/auto_pipeline.py --dry-run --videos 10

# Solo descargar, sin procesar
python scripts/auto_pipeline.py --download-only --videos 5

# Procesar solo una categorÃ­a
python scripts/auto_pipeline.py --category podcasts_medicina --videos 10

# Reprocesar videos que fallaron
python scripts/auto_pipeline.py --retry-failed

# Limpiar registro de fallidos
python scripts/auto_pipeline.py --reset-failed
```

#### Opciones del Auto Pipeline

| OpciÃ³n | DescripciÃ³n |
|--------|-------------|
| `--videos N` | NÃºmero total de videos a descargar (default: 10) |
| `--dry-run` | Solo mostrar quÃ© se descargarÃ­a |
| `--download-only` | Solo descargar, no procesar |
| `--category NAME` | Procesar solo una categorÃ­a |
| `--limit N` | MÃ¡ximo videos por query de bÃºsqueda |
| `--retry-failed` | Reprocesar videos fallidos |
| `--reset-failed` | Limpiar registro de videos fallidos |
| `--data-path PATH` | Ruta donde guardar datos |

### 2. Procesamiento Manual

Para procesar archivos de audio existentes:

```bash
# Procesar un archivo
python main.py /ruta/al/podcast.wav -o ./output

# Procesar un directorio
python main.py /ruta/a/directorio/ -o ./output

# Con configuraciÃ³n personalizada
python main.py archivo.wav -o ./output -c ./config/mi_config.json
```

### 3. Descarga de Videos

Para descargar videos individualmente:

```bash
python scripts/download_video.py "URL_DEL_VIDEO" -o ./data/input --format wav
```

## âš™ï¸ ConfiguraciÃ³n

### config/config.json

```json
{
  "min_duration": 5.0,              // DuraciÃ³n mÃ­nima de segmentos (segundos)
  "max_duration": 15.0,             // DuraciÃ³n mÃ¡xima de segmentos
  "target_sr": 22050,               // Sample rate objetivo (Hz)
  "target_lufs": -23.0,             // Nivel LUFS objetivo
  "whisper_model": "base",          // Modelo Whisper: tiny, base, small, medium, large
  "use_diarization": true,          // Habilitar diarizaciÃ³n
  "hf_token": "hf_xxx",             // Token de Hugging Face
  "use_voice_bank": true,           // Reutilizar voces conocidas
  "use_segment_review": true,       // Segunda etapa de revisiÃ³n
  "text_preprocessing": {
    "enabled": true,
    "fix_punctuation": true,
    "normalize_numbers": true
  },
  "llm_correction": {
    "enabled": true,
    "ollama_host": "http://localhost:11434",
    "model": "qwen3:8b",
    "use_batch": true,
    "batch_size": 5,
    "enable_cache": true,
    "cache_file": "./llm_cache.json"
  }
}
```

### config/search_queries.json

Define las categorÃ­as de bÃºsqueda para el auto pipeline:

```json
{
  "search_settings": {
    "max_results_per_query": 5,
    "min_duration_minutes": 10,
    "max_duration_minutes": 180
  },
  "categories": [
    {
      "name": "podcasts_negocios",
      "enabled": true,
      "queries": [
        "podcast emprendimiento espaÃ±ol",
        "podcast marketing digital espaÃ±ol"
      ],
      "exclude_keywords": ["shorts", "clip"]
    }
  ]
}
```

## ğŸ“Š Salida Generada

```
Base de Datos - Voz/
â”œâ”€â”€ input/                         # Audios descargados
â”‚   â””â”€â”€ podcast_ejemplo.wav
â”œâ”€â”€ normalized/                    # Segmentos procesados
â”‚   â””â”€â”€ podcast_ejemplo/
â”‚       â”œâ”€â”€ seg_0000_SPK_00.wav
â”‚       â”œâ”€â”€ seg_0001_SPK_01.wav
â”‚       â””â”€â”€ ...
â”œâ”€â”€ metadata/                      # Metadata por podcast
â”‚   â””â”€â”€ podcast_ejemplo.json
â”œâ”€â”€ logs/                          # Logs de procesamiento
â”‚   â””â”€â”€ podcast_ejemplo.log
â”œâ”€â”€ metadata.json                  # Metadata consolidada
â”œâ”€â”€ voice_bank.json                # Banco de voces conocidas
â”œâ”€â”€ processed_videos.json          # Registro de videos procesados
â””â”€â”€ pipeline_report_*.png          # GrÃ¡ficas de reporte
```

### Formato de Metadata

```json
[
  {
    "text": "TranscripciÃ³n del segmento",
    "path": "/ruta/absoluta/al/archivo.wav",
    "speaker": 0,
    "speaker_label": "SPK_00",
    "start": 0.0,
    "end": 12.5,
    "duration": 12.5,
    "language": "es",
    "podcast_id": "nombre_podcast",
    "segment_id": "seg_0000_SPK_00"
  }
]
```

## ğŸ“ˆ Reportes y GrÃ¡ficas

Al finalizar el procesamiento, se genera automÃ¡ticamente una grÃ¡fica con:

- **Resumen General**: Videos procesados, audio total, audio Ãºtil
- **DuraciÃ³n vs Tiempo de Procesamiento**: Por cada video
- **Audio Total vs Audio Ãštil**: Eficiencia del procesamiento
- **EstadÃ­sticas Detalladas**: MÃ©tricas completas

## ğŸ”§ Pipeline de Procesamiento

1. **DiarizaciÃ³n** â†’ Identifica hablantes en el audio
2. **SegmentaciÃ³n** â†’ Divide en clips de 5-15 segundos
3. **NormalizaciÃ³n** â†’ Ajusta volumen y sample rate
4. **TranscripciÃ³n** â†’ Convierte audio a texto (Whisper)
5. **Preprocesamiento** â†’ Limpia puntuaciÃ³n, nÃºmeros (diccionarios)
6. **CorrecciÃ³n LLM** â†’ Verifica y corrige texto (batch + cachÃ©)
7. **ValidaciÃ³n** â†’ Verifica estructura con Pydantic
8. **GeneraciÃ³n Metadata** â†’ Crea archivos JSON

### Optimizaciones del LLM

| CaracterÃ­stica | DescripciÃ³n | Impacto |
|----------------|-------------|---------|
| **Batch Processing** | Agrupa 5 textos por llamada | 80% menos HTTP calls |
| **CachÃ© Persistente** | Guarda correcciones en JSON | Instant en repetidos |
| **Paralelo** | ThreadPoolExecutor opcional | 3-4x mÃ¡s rÃ¡pido |
| **Pydantic** | ValidaciÃ³n de respuestas | <1% errores parsing |

## ğŸ› SoluciÃ³n de Problemas

### Error de conversiÃ³n de audio (ffmpeg snap)
El script automÃ¡ticamente usa `/usr/bin/ffmpeg` en lugar del ffmpeg de snap para evitar problemas de permisos.

### Warnings de Lightning
Los warnings de PyTorch Lightning son filtrados automÃ¡ticamente y no detienen el procesamiento.

### Videos fallidos
Usa `--retry-failed` para reprocesar videos que fallaron:
```bash
python scripts/auto_pipeline.py --retry-failed
```

### Token de Hugging Face
Para diarizaciÃ³n, necesitas un token de HuggingFace:
1. Crea cuenta en https://huggingface.co
2. Acepta tÃ©rminos de pyannote/speaker-diarization
3. Genera token en https://huggingface.co/settings/tokens
4. AÃ±Ã¡delo a config.json

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.

## ğŸ”— Referencias

- [Whisper](https://github.com/openai/whisper) - TranscripciÃ³n
- [pyannote.audio](https://github.com/pyannote/pyannote-audio) - DiarizaciÃ³n
- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - Descarga de videos
- [Ollama](https://ollama.ai/) - CorrecciÃ³n con LLM
