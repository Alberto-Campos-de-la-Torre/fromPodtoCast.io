# ðŸš€ GuÃ­a RÃ¡pida - Probar fromPodtoCast

## Paso 1: Verificar Dependencias

```bash
cd /home/ttech-main/fromPodtoCast
python3 scripts/check_dependencies.py
```

Si faltan dependencias, instÃ¡lalas:
```bash
pip install -r requirements-minimal.txt  # Si ya tienes PyTorch
# O
pip install -r requirements.txt  # InstalaciÃ³n completa
```

## Paso 2: Preparar Archivo de Audio de Prueba

Tienes dos opciones:

### OpciÃ³n A: Usar un archivo existente
Coloca tu archivo de podcast en `data/input/`:
```bash
# Copiar un archivo de audio (ejemplo)
cp /ruta/a/tu/podcast.mp3 data/input/
```

### OpciÃ³n B: Usar archivos de prueba del proyecto Local-csm
Si tienes archivos de audio en Local-csm:
```bash
# Copiar archivos de prueba
cp /home/ttech-main/csm/Local-csm/data/audio/*.wav data/input/ 2>/dev/null || echo "No hay archivos en Local-csm/data/audio"
```

## Paso 3: Configurar (Opcional)

Edita `config/config.json` si necesitas ajustar parÃ¡metros:
- `whisper_model`: "tiny" (rÃ¡pido), "base" (recomendado), "small", "medium", "large"
- `min_duration` / `max_duration`: DuraciÃ³n de segmentos (10-15 segundos por defecto)
- `language`: Idioma del audio (null = auto-detectar)

## Paso 4: Ejecutar el Procesador

### Procesar un archivo individual:
```bash
python3 main.py data/input/tu_archivo.mp3 -o data/output
```

### Procesar todos los archivos de un directorio:
```bash
python3 main.py data/input/ -o data/output
```

### Con metadata personalizado:
```bash
python3 main.py data/input/tu_archivo.mp3 -o data/output --metadata data/output/train_metadata.json
```

## Paso 5: Verificar Resultados

DespuÃ©s de la ejecuciÃ³n, deberÃ­as ver:

```
data/output/
â”œâ”€â”€ segments/
â”‚   â””â”€â”€ nombre_podcast/
â”‚       â”œâ”€â”€ nombre_podcast_segment_0000.wav
â”‚       â”œâ”€â”€ nombre_podcast_segment_0001.wav
â”‚       â””â”€â”€ ...
â”œâ”€â”€ normalized/
â”‚   â””â”€â”€ nombre_podcast/
â”‚       â”œâ”€â”€ nombre_podcast_segment_0000.wav
â”‚       â”œâ”€â”€ nombre_podcast_segment_0001.wav
â”‚       â””â”€â”€ ...
â””â”€â”€ metadata.json
```

### Ver el archivo de metadata:
```bash
cat data/output/metadata.json | head -50
```

### Verificar un segmento de audio:
```bash
# Reproducir un segmento (si tienes un reproductor instalado)
# o verificar con librosa
python3 -c "import librosa; import soundfile as sf; audio, sr = librosa.load('data/output/normalized/nombre_podcast/nombre_podcast_segment_0000.wav'); print(f'Sample rate: {sr} Hz, DuraciÃ³n: {len(audio)/sr:.2f}s')"
```

## Paso 6: Usar el Metadata para Entrenamiento

El archivo `metadata.json` generado es compatible con:
- **Sesame1b**: Usa directamente el archivo JSON
- **Kyutai TTS**: Puede requerir ajustes menores segÃºn el formato especÃ­fico

### Ejemplo de uso con Sesame1b:
```bash
# El archivo metadata.json ya estÃ¡ en el formato correcto
# Puedes usarlo directamente en pretokenize.py de Sesame
python pretokenize.py --train_data data/output/metadata.json --val_data data/output/metadata.json --output tokenized_data.hdf5
```

## SoluciÃ³n de Problemas

### Error: "No module named 'whisper'"
```bash
pip install openai-whisper
```

### Error: "ffmpeg not found"
```bash
sudo apt-get install ffmpeg
```

### Error: "CUDA out of memory"
- Usa un modelo Whisper mÃ¡s pequeÃ±o: `"whisper_model": "tiny"` en config.json
- O procesa archivos mÃ¡s pequeÃ±os

### Audio sin transcripciÃ³n
- Verifica que el audio tenga suficiente volumen
- Prueba con un modelo Whisper mÃ¡s grande
- Verifica que el archivo de audio no estÃ© corrupto

## PrÃ³ximos Pasos

1. âœ… Procesar tus primeros podcasts
2. âœ… Revisar la calidad de las transcripciones
3. âœ… Ajustar parÃ¡metros en `config/config.json` segÃºn necesites
4. âœ… Usar el metadata.json para entrenar tus modelos TTS

## Notas

- El primer uso de Whisper descargarÃ¡ el modelo (puede tardar)
- El procesamiento puede tardar segÃºn la duraciÃ³n del audio
- Los segmentos se guardan en `data/output/segments/` y `data/output/normalized/`
- El archivo final `metadata.json` contiene todas las rutas absolutas

