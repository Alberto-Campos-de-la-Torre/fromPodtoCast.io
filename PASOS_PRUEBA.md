# üìã Pasos para Probar fromPodtoCast

## ‚úÖ Paso 1: Instalar Dependencias

### Opci√≥n A: Si ya tienes PyTorch instalado (recomendado)
```bash
cd /home/ttech-main/fromPodtoCast
pip install -r requirements-minimal.txt
```

### Opci√≥n B: Instalaci√≥n completa
```bash
cd /home/ttech-main/fromPodtoCast
pip install -r requirements.txt
```

### Verificar instalaci√≥n:
```bash
python3 scripts/check_dependencies.py
```

---

## ‚úÖ Paso 2: Ejecutar Prueba R√°pida

Verifica que todos los m√≥dulos funcionen:
```bash
python3 scripts/test_example.py
```

Deber√≠as ver: `üéâ ¬°Todas las pruebas pasaron!`

---

## ‚úÖ Paso 3: Preparar Archivo de Audio

### Opci√≥n A: Usar archivos existentes de Local-csm
```bash
# Copiar archivos de audio de prueba
cp /home/ttech-main/csm/Local-csm/data/audio/*.wav /home/ttech-main/fromPodtoCast/data/input/ 2>/dev/null

# Verificar que se copiaron
ls -lh /home/ttech-main/fromPodtoCast/data/input/
```

### Opci√≥n B: Usar tu propio archivo
```bash
# Copiar tu archivo de podcast
cp /ruta/a/tu/podcast.mp3 /home/ttech-main/fromPodtoCast/data/input/
```

---

## ‚úÖ Paso 4: Procesar un Archivo de Prueba

### Procesar un archivo individual:
```bash
cd /home/ttech-main/fromPodtoCast

# Si tienes archivos en data/input/
python3 main.py data/input/audio20.wav -o data/output
```

### O procesar todos los archivos del directorio:
```bash
python3 main.py data/input/ -o data/output
```

### Lo que ver√°s durante la ejecuci√≥n:
```
============================================================
Procesando podcast: audio20.wav
============================================================

1. Segmentando audio...
   ‚úì Generados X segmentos

2. Normalizando segmentos...
   Normalizando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| X/X [00:XX<00:00, X.XXit/s]
   ‚úì Normalizados X segmentos

3. Transcribiendo segmentos...
   Transcribiendo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| X/X [00:XX<00:00, X.XXit/s]
   ‚úì Transcritos X segmentos

4. Generando metadatos finales...
   ‚úì Generados X registros de metadata

============================================================
‚úì Metadata guardado en: data/output/metadata.json
  Total de registros: X
============================================================
```

---

## ‚úÖ Paso 5: Verificar Resultados

### Ver la estructura generada:
```bash
tree data/output/ -L 3
# O si no tienes tree:
ls -R data/output/
```

### Ver el archivo de metadata:
```bash
# Ver primeras l√≠neas
head -30 data/output/metadata.json

# Ver todo el archivo (si es peque√±o)
cat data/output/metadata.json | python3 -m json.tool
```

### Verificar un segmento de audio:
```bash
# Ver informaci√≥n de un segmento
python3 -c "
import librosa
import soundfile as sf
audio, sr = librosa.load('data/output/normalized/audio20/audio20_segment_0000.wav')
print(f'Sample rate: {sr} Hz')
print(f'Duraci√≥n: {len(audio)/sr:.2f} segundos')
print(f'Forma: {audio.shape}')
"
```

### Contar segmentos generados:
```bash
# Contar segmentos normalizados
find data/output/normalized -name "*.wav" | wc -l

# Ver tama√±o total
du -sh data/output/
```

---

## ‚úÖ Paso 6: Revisar Metadata Generado

El archivo `metadata.json` deber√≠a tener este formato:

```json
[
  {
    "text": "Transcripci√≥n del segmento...",
    "path": "/ruta/absoluta/al/archivo.wav",
    "speaker": 0,
    "speaker_label": "SPEAKER_00",
    "start": 0.0,
    "end": 12.5,
    "duration": 12.5,
    "language": "es",
    "podcast_id": "audio20"
  }
]
```

### Verificar que las transcripciones sean correctas:
```bash
# Extraer solo los textos
cat data/output/metadata.json | python3 -c "
import json, sys
data = json.load(sys.stdin)
for i, item in enumerate(data[:5]):  # Primeros 5
    print(f'{i+1}. {item[\"text\"][:100]}...')
"
```

---

## üîß Soluci√≥n de Problemas

### Error: "No module named 'librosa'"
```bash
pip install librosa soundfile
```

### Error: "ffmpeg not found"
```bash
sudo apt-get install ffmpeg
```

### Error: "CUDA out of memory"
Edita `config/config.json`:
```json
{
  "whisper_model": "tiny"  // Cambiar de "base" a "tiny"
}
```

### Audio sin transcripci√≥n
- Verifica que el audio tenga volumen suficiente
- Prueba con un modelo Whisper m√°s grande: `"whisper_model": "small"`

### Procesamiento muy lento
- Usa modelo Whisper m√°s peque√±o: `"whisper_model": "tiny"`
- Procesa archivos m√°s cortos primero

---

## üìä Ejemplo Completo de Uso

```bash
# 1. Ir al directorio del proyecto
cd /home/ttech-main/fromPodtoCast

# 2. Instalar dependencias (si no est√°n)
pip install -r requirements-minimal.txt

# 3. Copiar archivo de prueba
cp /home/ttech-main/csm/Local-csm/data/audio/audio20.wav data/input/

# 4. Procesar
python3 main.py data/input/audio20.wav -o data/output

# 5. Ver resultados
cat data/output/metadata.json | head -50
```

---

## üéØ Pr√≥ximos Pasos

Una vez que tengas el `metadata.json` generado:

1. **Para Sesame1b**: Usa directamente el archivo JSON
   ```bash
   python pretokenize.py --train_data data/output/metadata.json --val_data data/output/metadata.json --output tokenized_data.hdf5
   ```

2. **Para Kyutai TTS**: Puede requerir ajustes menores seg√∫n el formato espec√≠fico

3. **Mejorar calidad**: 
   - Ajusta `min_duration` y `max_duration` en `config/config.json`
   - Usa modelo Whisper m√°s grande para mejor transcripci√≥n
   - Habilita diarizaci√≥n si tienes m√∫ltiples hablantes

---

## üìù Notas Importantes

- El primer uso de Whisper descargar√° el modelo (puede tardar unos minutos)
- El procesamiento puede tardar seg√∫n la duraci√≥n del audio
- Los segmentos se guardan en `data/output/segments/` (temporales) y `data/output/normalized/` (finales)
- El archivo `metadata.json` contiene rutas absolutas a los archivos normalizados

